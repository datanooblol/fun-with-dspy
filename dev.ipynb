{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46b9735",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac4b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8790d9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db90c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.base import DSPyChoice, DSPyResult, DriverLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f980a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def llama_prompt_fn(messages: list[dict]) -> str:\n",
    "    # DSPy puts the full formatted prompt in the last message\n",
    "    return messages[-1]['content'] if messages else \"\"\n",
    "\n",
    "\n",
    "def llama_request_fn(prompt: str, temperature: float = 0.0, max_tokens: int | None = None) -> dict:\n",
    "    # model = \"llama3.2:1b\"\n",
    "    model = \"llama3.2-vision:11b\"\n",
    "    response = requests.post(\n",
    "        'http://localhost:11434/api/chat',  # Changed to /chat\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],  # Changed format\n",
    "            \"stream\": False,\n",
    "            \"options\": {\"temperature\": temperature}\n",
    "        }\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    # Extract text from chat response\n",
    "    return {\"response\": data[\"message\"][\"content\"]}\n",
    "\n",
    "def llama_output_fn(response:dict)->DSPyResult:\n",
    "    text = response.get(\"response\", \"\").strip()\n",
    "    return DSPyResult(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9254b5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [<package.base.DSPyChoice at 0x209f9c1a090>]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = llama_prompt_fn([{\"role\":\"user\",\"content\":\"hello\"}])\n",
    "response = llama_request_fn(prompt)\n",
    "response = llama_output_fn(response)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d9f3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response['choices'][0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3ca3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = DriverLM(\n",
    "    request_fn=llama_request_fn,\n",
    "    prompt_fn=llama_prompt_fn,\n",
    "    output_fn=llama_output_fn,\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7086f0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [<package.base.DSPyChoice at 0x209f9e31790>]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.forward(messages=[{\"role\":\"user\", \"content\":\"hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "468cb4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(messages=[{\"role\":\"user\", \"content\":\"hello\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff49d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello. How can I assist you today?']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Configure DSPy with Ollama\n",
    "lm = dspy.LM(\n",
    "    model=\"ollama/llama3.2:1b\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=500\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Use it\n",
    "response = lm(messages=[{\"role\": \"user\", \"content\": \"hello\"}])\n",
    "print(response)\n",
    "\n",
    "# Or with DSPy modules\n",
    "predict = dspy.Predict(\"question -> answer\")\n",
    "result = predict(question=\"What is 2+2?\")\n",
    "print(result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b2477fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='2'\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8e78390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello! How can I assist you today?']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "lm = DriverLM(\n",
    "    request_fn=llama_request_fn,\n",
    "    prompt_fn=llama_prompt_fn,\n",
    "    output_fn=llama_output_fn,\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Use it\n",
    "response = lm(messages=[{\"role\": \"user\", \"content\": \"hello\"}])\n",
    "print(response)\n",
    "\n",
    "# Or with DSPy modules\n",
    "predict = dspy.Predict(\"question -> answer\")\n",
    "result = predict(question=\"What is 2+2?\")\n",
    "print(result.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b41e653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='4'\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce14b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Paris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Paris'\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Configure with your DriverLM\n",
    "lm = DriverLM(\n",
    "    request_fn=llama_request_fn,\n",
    "    prompt_fn=llama_prompt_fn,\n",
    "    output_fn=llama_output_fn,\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Define a signature\n",
    "class QA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "# Use it\n",
    "qa = dspy.Predict(QA)\n",
    "result = qa(question=\"What is the capital of France?\")\n",
    "print(f\"Answer: {result.answer}\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e2791d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='To find the product of 15 and 23, we can simply multiply these two numbers together.\\n\\n15 * 23 = 345',\n",
       "    answer='345'\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with ChainOfThought\n",
    "cot = dspy.ChainOfThought(QA)\n",
    "result2 = cot(question=\"What is 15 * 23?\")\n",
    "# print(f\"Reasoning: {result2.rationale}\")\n",
    "# print(f\"Answer: {result2.answer}\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e5554bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['reasoning', 'answer']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='This multiplication problem can be solved by simply multiplying the numbers together.',\n",
       "    answer='The result of this calculation is 345.'\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with native dspy.LM\n",
    "lm = dspy.LM(\n",
    "    model=\"ollama/llama3.2:1b\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=500\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "cot = dspy.ChainOfThought(QA)\n",
    "result = cot(question=\"What is 15 * 23?\")\n",
    "\n",
    "# Check if reasoning exists\n",
    "print(\"Keys:\", result.keys())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3320fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:00<00:00, 49.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Emotion: happy\n",
      "Reasoning: The sentence contains the word \"excited\", which is typically associated with positive emotions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The sentence contains the word \"love\", which is typically associated with positive emotions, and the word \"pizza\" is a common topic of enjoyment.',\n",
       "    emotion='happy'\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Native LM from dspy\n",
    "lm = dspy.LM(\n",
    "    model=\"ollama/llama3.2-vision:11b\",\n",
    "    api_base=\"http://localhost:11434\",\n",
    "    temperature=0.0,\n",
    "    max_tokens=500\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Define signature\n",
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"Classify the emotion of a sentence.\"\"\"\n",
    "    sentence = dspy.InputField()\n",
    "    emotion = dspy.OutputField(desc=\"happy, sad, or neutral\")\n",
    "\n",
    "# Create training data\n",
    "trainset = [\n",
    "    dspy.Example(sentence=\"I love this!\", emotion=\"happy\").with_inputs(\"sentence\"),\n",
    "    dspy.Example(sentence=\"This is terrible.\", emotion=\"sad\").with_inputs(\"sentence\"),\n",
    "    dspy.Example(sentence=\"It's okay.\", emotion=\"neutral\").with_inputs(\"sentence\"),\n",
    "]\n",
    "\n",
    "# Create module\n",
    "class EmotionClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.prog = dspy.ChainOfThought(Emotion)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        return self.prog(sentence=sentence)\n",
    "\n",
    "# Optimize\n",
    "optimizer = BootstrapFewShot(max_bootstrapped_demos=2, max_labeled_demos=2)\n",
    "optimized = optimizer.compile(EmotionClassifier(), trainset=trainset)\n",
    "\n",
    "# Test\n",
    "result = optimized(sentence=\"I'm so excited!\")\n",
    "print(f\"Emotion: {result.emotion}\")\n",
    "print(f\"Reasoning: {result.reasoning}\")\n",
    "optimized(sentence=\"I love pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a45e9f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Emotion: The primary emotion expressed in this sentence is excitement, which is a strong and positive feeling of eagerness or anticipation.\n",
      "Reasoning: The sentence \"I'm so excited!\" is a common expression used to convey enthusiasm or eagerness about something, often in a lighthearted or playful manner.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The sentence \"I love pizza\" is a statement expressing a positive sentiment towards pizza, indicating a strong affection or enjoyment for it.',\n",
       "    emotion='The emotion expressed in the sentence is love, which is a strong and positive feeling.'\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "# Configure your DriverLM\n",
    "lm = DriverLM(\n",
    "    request_fn=llama_request_fn,\n",
    "    prompt_fn=llama_prompt_fn,\n",
    "    output_fn=llama_output_fn,\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Define signature\n",
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"Classify the emotion of a sentence.\"\"\"\n",
    "    sentence = dspy.InputField()\n",
    "    emotion = dspy.OutputField(desc=\"happy, sad, or neutral\")\n",
    "\n",
    "# Create training data\n",
    "trainset = [\n",
    "    dspy.Example(sentence=\"I love this!\", emotion=\"happy\").with_inputs(\"sentence\"),\n",
    "    dspy.Example(sentence=\"This is terrible.\", emotion=\"sad\").with_inputs(\"sentence\"),\n",
    "    dspy.Example(sentence=\"It's okay.\", emotion=\"neutral\").with_inputs(\"sentence\"),\n",
    "]\n",
    "\n",
    "# Create module\n",
    "class EmotionClassifier(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.prog = dspy.ChainOfThought(Emotion)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        return self.prog(sentence=sentence)\n",
    "\n",
    "# Optimize\n",
    "optimizer = BootstrapFewShot(max_bootstrapped_demos=2, max_labeled_demos=2)\n",
    "optimized = optimizer.compile(EmotionClassifier(), trainset=trainset)\n",
    "\n",
    "# Test\n",
    "result = optimized(sentence=\"I'm so excited!\")\n",
    "print(f\"Emotion: {result.emotion}\")\n",
    "print(f\"Reasoning: {result.reasoning}\")\n",
    "optimized(sentence=\"I love pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bda72f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The sentence \"I love pizza\" is a statement expressing a positive sentiment towards pizza, indicating a strong affection or enjoyment for it.',\n",
       "    emotion='The emotion expressed in the sentence is love, which is a strong and positive feeling.'\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized(sentence=\"I love pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb97c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimized Module ===\n",
      "\n",
      "prog.predict:\n",
      "Signature: StringSignature(sentence -> reasoning, emotion\n",
      "    instructions='Classify the emotion of a sentence.'\n",
      "    sentence = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Sentence:', 'desc': '${sentence}'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    emotion = Field(annotation=str required=True json_schema_extra={'desc': 'happy, sad, or neutral', '__dspy_field_type': 'output', 'prefix': 'Emotion:'})\n",
      ")\n",
      "Demos: 2 examples\n",
      "  Demo 1: Example({'augmented': True, 'sentence': 'I love this!', 'reasoning': 'The sentence contains the word \"love\", which is typically associated with positive emotions.', 'emotion': 'happy'}) (input_keys=None)\n",
      "  Demo 2: Example({'augmented': True, 'sentence': 'This is terrible.', 'reasoning': 'The sentence contains the word \"terrible\", which is a strong negative word, indicating a strong negative emotion.', 'emotion': 'sad'}) (input_keys=None)\n",
      "\n",
      "Saved to emotion_classifier.json\n",
      "\n",
      "=== Quick Check ===\n",
      "Module type: <class '__main__.EmotionClassifier'>\n",
      "Has prog: True\n",
      "Prog demos: 0\n"
     ]
    }
   ],
   "source": [
    "# After optimization\n",
    "# optimized = optimizer.compile(EmotionClassifier(), trainset=trainset)\n",
    "\n",
    "# 1. Inspect the optimized prompts\n",
    "print(\"=== Optimized Module ===\")\n",
    "for name, predictor in optimized.named_predictors():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Signature: {predictor.signature}\")\n",
    "    if hasattr(predictor, 'demos'):\n",
    "        print(f\"Demos: {len(predictor.demos)} examples\")\n",
    "        for i, demo in enumerate(predictor.demos):\n",
    "            print(f\"  Demo {i+1}: {demo}\")\n",
    "\n",
    "# 2. Save the optimized module\n",
    "optimized.save(\"emotion_classifier.json\")\n",
    "print(\"\\nSaved to emotion_classifier.json\")\n",
    "\n",
    "# 3. Load it later\n",
    "loaded = EmotionClassifier()\n",
    "loaded.load(\"emotion_classifier.json\")\n",
    "\n",
    "# 4. Simple inspection\n",
    "print(\"\\n=== Quick Check ===\")\n",
    "print(f\"Module type: {type(optimized)}\")\n",
    "print(f\"Has prog: {hasattr(optimized, 'prog')}\")\n",
    "if hasattr(optimized, 'prog'):\n",
    "    print(f\"Prog demos: {len(optimized.prog.demos) if hasattr(optimized.prog, 'demos') else 0}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fun-with-dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
