{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a05cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c10a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clear DSPy's global disk cache\n",
    "if hasattr(dspy, 'cache') and hasattr(dspy.cache, 'disk_cache'):\n",
    "    dspy.cache.disk_cache.clear()\n",
    "    print(\"clear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d79c1",
   "metadata": {},
   "source": [
    "# Ollama solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1afacc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.base import DriverLM, ModelResponse, Usage\n",
    "import httpx\n",
    "\n",
    "ollama_client = httpx.Client(timeout=600.0)\n",
    "def ollama_request_fn(prompt: str | None = None, messages: list[dict] | None = None, temperature: float = 0.0, max_tokens: int = 256):\n",
    "    if messages is None:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Ollama expects images in a specific format\n",
    "    processed_messages = []\n",
    "    for msg in messages:\n",
    "        content = msg[\"content\"]\n",
    "        \n",
    "        # Handle multi-part content (text + images)\n",
    "        if isinstance(content, list):\n",
    "            # Extract text and images\n",
    "            text_parts = [part[\"text\"] for part in content if part.get(\"type\") == \"text\"]\n",
    "            image_parts = [part[\"image_url\"][\"url\"] for part in content if part.get(\"type\") == \"image_url\"]\n",
    "            \n",
    "            processed_msg = {\n",
    "                \"role\": msg[\"role\"],\n",
    "                \"content\": \" \".join(text_parts)\n",
    "            }\n",
    "            \n",
    "            # Ollama uses \"images\" field for base64 data\n",
    "            if image_parts:\n",
    "                processed_msg[\"images\"] = [\n",
    "                    img.split(\",\")[1] if \"base64,\" in img else img  # Extract base64 part\n",
    "                    for img in image_parts\n",
    "                ]\n",
    "            \n",
    "            processed_messages.append(processed_msg)\n",
    "        else:\n",
    "            # Simple text message\n",
    "            processed_messages.append(msg)\n",
    "    \n",
    "    response = ollama_client.post(\n",
    "        'http://localhost:11434/api/chat',\n",
    "        json={\n",
    "            \"model\": \"llama3.2-vision:11b\",\n",
    "            \"messages\": processed_messages,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\"temperature\": temperature}\n",
    "        }\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def ollama_output_fn(response: dict) -> ModelResponse:\n",
    "    content = response.get(\"message\", {}).get(\"content\", \"\")\n",
    "    model = response.get(\"model\", \"custom\")\n",
    "    \n",
    "    usage = Usage(\n",
    "        prompt_tokens=response.get(\"prompt_eval_count\", 0),\n",
    "        completion_tokens=response.get(\"eval_count\", 0),\n",
    "        total_tokens=response.get(\"prompt_eval_count\", 0) + response.get(\"eval_count\", 0)\n",
    "    )\n",
    "    \n",
    "    return ModelResponse.from_text(text=content.strip(), usage=usage, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3276d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A serene beach scene with a palm tree on the left side, a single lounge chair with a beige umbrella to its right, and a small patch of green foliage behind it. The background features a vast expanse of white sand leading up to a tranquil turquoise ocean, set against a bright blue sky with a few wispy clouds.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from package.base import DriverLM\n",
    "\n",
    "# Setup\n",
    "lm = DriverLM(\n",
    "    request_fn=ollama_request_fn,  # Updated to handle images\n",
    "    output_fn=ollama_output_fn,\n",
    "    cache=True\n",
    ")\n",
    "lm.clear_cache()  # Clear old cache entries\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Use it\n",
    "class SceneDescription(dspy.Signature):\n",
    "    \"\"\"Describe the contents of an image in detail.\"\"\"\n",
    "    image: dspy.Image = dspy.InputField(desc=\"Image to describe\")\n",
    "    scene_description: str = dspy.OutputField(desc=\"Detailed description\")\n",
    "\n",
    "describe = dspy.Predict(SceneDescription)\n",
    "img = dspy.Image(\"./images/beach.jpg\")\n",
    "result = describe(image=img)\n",
    "print(result.scene_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe8b938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(url=data:image/jpeg;base64,<IMAGE_BASE_64_ENCODED(49224)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0addb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a serene and picturesque scene, with a majestic mountain looming in the background, its snow-capped peak glistening in the sunlight. The mountain's rugged terrain is accentuated by the surrounding landscape, which features lush greenery and a tranquil lake that reflects the mountain's majestic form. The sky above is a brilliant blue, with only a few wispy clouds scattered across it, adding to the sense of tranquility and peacefulness that pervades the scene. The overall atmosphere is one of natural beauty and wonder, inviting the viewer to step into the idyllic world captured in the image.\n"
     ]
    }
   ],
   "source": [
    "# Read image file as bytes\n",
    "with open(\"images/lake_mountain.jpg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "# Create Image from bytes\n",
    "img = dspy.Image(image_bytes)\n",
    "result = describe(image=img)\n",
    "print(result.scene_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d128d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(url=data:image/jpeg;base64,<IMAGE_BASE_64_ENCODED(17836)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeec511",
   "metadata": {},
   "source": [
    "# Bedrock solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe6e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import base64\n",
    "from typing import Any\n",
    "\n",
    "def bedrock_request_fn(prompt: str | None = None, messages: list[dict] | None = None, temperature: float = 0.0, max_tokens: int = 2048):\n",
    "    client = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "    \n",
    "    if messages is None:\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    system_messages = []\n",
    "    conversation_messages = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"system\":\n",
    "            system_messages.append({\"text\": msg[\"content\"]})\n",
    "        else:\n",
    "            content = msg[\"content\"]\n",
    "            \n",
    "            # Handle multi-part content (text + images)\n",
    "            if isinstance(content, list):\n",
    "                bedrock_content = []\n",
    "                \n",
    "                for part in content:\n",
    "                    if part.get(\"type\") == \"text\":\n",
    "                        bedrock_content.append({\"text\": part[\"text\"]})\n",
    "                    \n",
    "                    elif part.get(\"type\") == \"image_url\":\n",
    "                        image_url = part[\"image_url\"][\"url\"]\n",
    "                        \n",
    "                        if image_url.startswith(\"data:\"):\n",
    "                            # Parse: \"data:image/jpeg;base64,...\" -> format + bytes\n",
    "                            header, data = image_url.split(\",\", 1)\n",
    "                            format_type = header.split(\";\")[0].split(\"/\")[1]  # \"jpeg\"\n",
    "                            image_bytes = base64.b64decode(data)\n",
    "                            \n",
    "                            bedrock_content.append({\n",
    "                                \"image\": {\n",
    "                                    \"format\": format_type,\n",
    "                                    \"source\": {\"bytes\": image_bytes}\n",
    "                                }\n",
    "                            })\n",
    "                \n",
    "                conversation_messages.append({\n",
    "                    \"role\": msg[\"role\"],\n",
    "                    \"content\": bedrock_content\n",
    "                })\n",
    "            else:\n",
    "                # Simple text message\n",
    "                conversation_messages.append({\n",
    "                    \"role\": msg[\"role\"],\n",
    "                    \"content\": [{\"text\": content}]\n",
    "                })\n",
    "    \n",
    "    request_params = {\n",
    "        \"modelId\": \"us.amazon.nova-lite-v1:0\",\n",
    "        \"messages\": conversation_messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"maxTokens\": max_tokens,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if system_messages:\n",
    "        request_params[\"system\"] = system_messages\n",
    "    \n",
    "    response = client.converse(**request_params)\n",
    "    return response\n",
    "\n",
    "def bedrock_output_fn(response: dict) -> ModelResponse:\n",
    "    content = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    model = response.get(\"ResponseMetadata\", {}).get(\"HTTPHeaders\", {}).get(\"x-amzn-bedrock-model-id\", \"bedrock-model\")\n",
    "    \n",
    "    usage_data = response.get(\"usage\", {})\n",
    "    usage = Usage(\n",
    "        prompt_tokens=usage_data.get(\"inputTokens\", 0),\n",
    "        completion_tokens=usage_data.get(\"outputTokens\", 0),\n",
    "        total_tokens=usage_data.get(\"totalTokens\", 0)\n",
    "    )\n",
    "    \n",
    "    return ModelResponse.from_text(text=content, usage=usage, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c8d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a stunning waterfall cascading down a rocky cliff in a lush, green forest. The waterfall is divided into two main streams that flow over the rocks, creating a series of small waterfalls and pools of water. The surrounding area is densely covered with green foliage, and the rocks are partially covered in moss and greenery. The sunlight filters through the canopy, casting dappled light on the scene, enhancing the natural beauty of the environment.\n"
     ]
    }
   ],
   "source": [
    "# Create Bedrock LM\n",
    "lm = DriverLM(\n",
    "    request_fn=bedrock_request_fn,\n",
    "    output_fn=bedrock_output_fn,\n",
    "    cache=True\n",
    ")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Use same code as Ollama\n",
    "describe = dspy.Predict(SceneDescription)\n",
    "img = dspy.Image(\"./images/forest_creak.jpeg\")\n",
    "result = describe(image=img)\n",
    "print(result.scene_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b9e670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image(url=data:image/jpeg;base64,<IMAGE_BASE_64_ENCODED(812056)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66496fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fun-with-dspy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
